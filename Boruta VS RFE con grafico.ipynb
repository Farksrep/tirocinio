{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importazione librerie utili\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from boruta import BorutaPy \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, precision_score, matthews_corrcoef, cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funzione per calcolare la specificità TrueNeg/TotSani\n",
    "\n",
    "def specificity_score(ypred,y):\n",
    "     tn, fp, fn, tp = confusion_matrix(ypred, y).ravel()\n",
    "    \n",
    "     return (tn/(tn+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funzione per calcolare la media\n",
    "def media (array, int):\n",
    "    c=0\n",
    "    for i in array:\n",
    "        c=c+i\n",
    "    return (c/int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(X_train_selected, y_train, cat_indexes):\n",
    "    sm=SMOTENC(random_state=41, categorical_features=cat_indexes)\n",
    "    X_train_selected_aug, y_train_aug = sm.fit_resample(X_train_selected, y_train)\n",
    "    return X_train_selected_aug, y_train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_boruta(X_train, y_train, X_test, colname, rf):\n",
    "    boruta_feature_selector = BorutaPy(rf, n_estimators='auto', verbose=0, max_iter = 50, perc = 40)\n",
    "    \n",
    "    #modello che prende in entrata x e la loro corrispondete uscita y e dice quali features sono rilevanti e quali no.\n",
    "    boruta_feature_selector.fit(X_train, y_train)\n",
    "    indexes = np.where(boruta_feature_selector.support_ == True)\n",
    "    #print(colname[indexes])\n",
    "    #quindi qui ho 270x20 e 30x20        \n",
    "    X_train_selected=boruta_feature_selector.transform(X_train)\n",
    "    #X_train_selected=X_train[:,indexes]\n",
    "    X_test_selected=boruta_feature_selector.transform(X_test)\n",
    "    \n",
    "    return indexes, X_train_selected, X_test_selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rfe(X_train,y_train, X_test,colname, rf):\n",
    "    selector = RFE(rf, n_features_to_select=20, step=3)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "              \n",
    "    X_train_selected=selector.transform(X_train)\n",
    "    X_test_selected=selector.transform(X_test)\n",
    "    indexes = np.where(selector.support_ == True) \n",
    "    #print(colname[indexes])\n",
    "    \n",
    "    return indexes,X_train_selected,X_test_selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 42)\n"
     ]
    }
   ],
   "source": [
    "#TUTTE LE VARIABILI\n",
    "#carico il dataset\n",
    "data = pd.read_csv(r'C:\\Users\\Utente\\anaconda3\\Lib\\site-packages\\pandas\\io\\data_covnet_score-imputed_missRF_increasing_1.txt')\n",
    "print(data.shape)\n",
    "\n",
    "# fisso il numero di iterazioni di cross-validation\n",
    "nit=15\n",
    "\n",
    "# fisso il numero di fold della cross vvalidation\n",
    "n_fold=10\n",
    "#creo un array di sole features\n",
    "features = np.array([f for f in data.columns if f not in ['LABEL']])\n",
    "\n",
    "#print(categorico)\n",
    "#creo un array con solo i valori delle features.\n",
    "X = data[features].values\n",
    "\n",
    "#ravel() mi fa diventare l'array monodimensionale.\n",
    "Y = data['LABEL'].values.ravel()\n",
    "\n",
    "#definisco una random forest\n",
    "rf = RandomForestClassifier(n_estimators = 101, max_depth=11, max_features=None, max_samples=0.75,class_weight=\"balanced\")\n",
    "\n",
    "\n",
    "#creo un array monodimensionale lungo quanto \"altri\" ma solo di 0. \n",
    "y_pred=np.zeros(Y.shape[0])\n",
    "ytrue = np.zeros(Y.shape[0])\n",
    "conta =np.zeros(Y.shape[0])\n",
    "\n",
    "#creo degli array che mi servono per creare i grafici, dove andrò a salvare le features che sono selezionate\n",
    "parzial_featuresboruta = []\n",
    "final_featuresboruta = list()\n",
    "parzial_featuresrfe = list()\n",
    "final_featuresrfe = list()\n",
    "    \n",
    "#creo degli array dove salvo di volta in volta il valore degli indici statistici\n",
    "spec=np.zeros(nit)\n",
    "sens = np.zeros(nit)\n",
    "f1=np.zeros(nit)\n",
    "acc=np.zeros(nit)\n",
    "prec=np.zeros(nit)\n",
    "matt =np.zeros(nit)\n",
    "choen=np.zeros(nit)    \n",
    "\n",
    "\n",
    "#DATA AUGMENTATION ?\n",
    "data_augmentation = True #False\n",
    "\n",
    "    \n",
    "#file_testo = open('prova.txt','w')\n",
    "#x = 2\n",
    "#y = 3\n",
    "#file_testo.write('Questa è una prova di scrivere 10 %f %f' %(x,y)) \n",
    "\n",
    "#print(X_train_selected_aug.shape) 500 22\n",
    "\n",
    "#file_testo.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boruta():\n",
    "    \n",
    "    for niter in range(nit):\n",
    "        skf = StratifiedKFold(n_splits=n_fold)\n",
    "\n",
    "        for train_index, test_index in skf.split(X, Y):\n",
    "               \n",
    "                # mi creo i punti di train (270) e di test (30) ad ogni iterazione cambiano \n",
    "                X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "                #creo le label del train e quelle del test (monodimensionale lungo 270 e 30)\n",
    "                y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "                #BORUTA\n",
    "               \n",
    "                indexes, X_train_selected, X_test_selected = apply_boruta(X_train, y_train, X_test,data.columns, rf)\n",
    "                indici=[]\n",
    "                for x in np.nditer(indexes):\n",
    "                    parzial_featuresboruta.append(features[x])\n",
    "                    indici.append(int(x))\n",
    "                    print(x)\n",
    "                    \n",
    "                if data_augmentation:\n",
    "                    cat_indexes = []\n",
    "                    #divido in categorici e numerici. i lo uso come indice, feature mi indica la i-esima feature \n",
    "                    print(indici)\n",
    "                    features_selected = features[indici] #Da 42 a 20\n",
    "                    for i, feature in enumerate(features_selected): #Itero con indice e feature solo sulle selezionate\n",
    "                        if feature.startswith('CAT'):\n",
    "                            cat_indexes.append(i)\n",
    "                            print(cat_indexes)\n",
    "\n",
    "\n",
    "                    X_train_selected_aug, y_train_aug = augmentation(X_train_selected, y_train, cat_indexes)\n",
    "                    clf = rf.fit(X_train_selected_aug, y_train_aug)\n",
    "                else:\n",
    "                    clf = rf.fit(X_train_selected, y_train)\n",
    "              \n",
    "                #y_pred=array di 300x1 0. Lo riempio di 30 alla volta andando a mettere la predizione basata su x_test_selected\n",
    "                y_pred[test_index] = clf.predict(X_test_selected)\n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #fine ciclo for train_index, test_index in skf.split(X, Y):\n",
    "\n",
    "        # QUI ho le predizioni ottenute con questpo split del dataset\n",
    "        #mi salvo il valore di ogni indice statistico, nell'array. Dovrò farne la media.\n",
    "        tp, tn, fp, fn = confusion_matrix(y_pred, Y).ravel()\n",
    "        f1[niter]=f1_score(y_pred,Y)\n",
    "        sens[niter] = recall_score(y_pred,Y)\n",
    "        acc[niter]=accuracy_score(y_pred,Y)\n",
    "        prec[niter]=precision_score(y_pred,Y)\n",
    "        matt[niter]=matthews_corrcoef(y_pred,Y)\n",
    "        choen[niter]=cohen_kappa_score(y_pred,Y)\n",
    "        spec[niter]=specificity_score(y_pred,Y)\n",
    "\n",
    "        #fine for niter in range(nit) -> \n",
    "\n",
    "   # X_filtered = boruta_feature_selector.transform(X)\n",
    "    #indexes = np.where(boruta_feature_selector.support_ == True)\n",
    "  \n",
    "\n",
    "    #stampo la media di tutti gli indici statistici per Boruta.\n",
    "    print(\"Specificità: \",media(spec,nit),\"F_score: \",media(f1,nit), \" Sens: \",media(sens,nit),\" Accuratezza: \", media(acc,nit), \" Precision: \",media(prec,nit), \" Matthews: \",media(matt,nit), \" Choen Kappa: \", media(choen, nit))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe():\n",
    "\n",
    "    for niter in range(nit):\n",
    "        skf = StratifiedKFold(n_splits=n_fold)\n",
    "\n",
    "        for train_index, test_index in skf.split(X, Y):\n",
    "            \n",
    "                # mi creo i punti di train e di test\n",
    "                X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "                #creo le label del train e quelle del test\n",
    "                y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "                \n",
    "                #RFE\n",
    "                \n",
    "                indexes, X_train_selected, X_test_selected=apply_rfe(X_train,y_train, X_test,data.columns, rf)\n",
    "\n",
    "\n",
    "                for x in np.nditer(indexes):\n",
    "                    parzial_featuresrfe.append(features[x])\n",
    "\n",
    "                clf = rf.fit(X_train_selected, y_train)\n",
    "\n",
    "                y_pred[test_index] =clf.predict(X_test_selected)\n",
    "             \n",
    "        #fine ciclo for train_index, test_index in skf.split(X, Y):\n",
    "\n",
    "        # QUI ho le predizioni ottenute con questo split del dataset\n",
    "        #mi salvo il valore di ogni indice statistico, nell'array. Dovrò farne la media.\n",
    "        tp, tn, fp, fn = confusion_matrix(y_pred, Y).ravel()\n",
    "        f1[niter]=f1_score(y_pred,Y)\n",
    "        sens[niter] = recall_score(y_pred,Y)\n",
    "        acc[niter]=accuracy_score(y_pred,Y)\n",
    "        prec[niter]=precision_score(y_pred,Y)\n",
    "        matt[niter]=matthews_corrcoef(y_pred,Y)\n",
    "        choen[niter]=cohen_kappa_score(y_pred,Y)\n",
    "        spec[niter]=specificity_score(y_pred,Y)\n",
    "\n",
    "    #fine for niter in range(nit) -> \n",
    "\n",
    "    #X_filtered = selector.transform(X)\n",
    "    #indexes = np.where(selector.support_ == True)\n",
    "    #stampo la media di tutti gli indici statistici per RFE.\n",
    "    print(\"Specificità: \",media(spec,nit),\"F_score: \",media(f1,nit), \" Sens: \",media(sens,nit),\" Accuratezza: \", media(acc,nit), \" Precision: \",media(prec,nit), \" Matthews: \",media(matt,nit), \" Choen Kappa: \", media(choen, nit))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "18\n",
      "22\n",
      "24\n",
      "25\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 18, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 1]\n",
      "8\n",
      "12\n",
      "19\n",
      "22\n",
      "24\n",
      "25\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 12, 19, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 2]\n",
      "8\n",
      "12\n",
      "15\n",
      "22\n",
      "24\n",
      "25\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 12, 15, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 2]\n",
      "8\n",
      "12\n",
      "15\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 12, 15, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 2]\n",
      "8\n",
      "19\n",
      "22\n",
      "24\n",
      "25\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 19, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 1]\n",
      "8\n",
      "12\n",
      "22\n",
      "24\n",
      "25\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 12, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "9\n",
      "12\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[9, 12, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "8\n",
      "15\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 15, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 1]\n",
      "12\n",
      "19\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[12, 19, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[1]\n",
      "8\n",
      "12\n",
      "19\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 12, 19, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 2]\n",
      "8\n",
      "18\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 18, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 1]\n",
      "8\n",
      "12\n",
      "15\n",
      "19\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 12, 15, 19, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 2]\n",
      "[0, 2, 3]\n",
      "8\n",
      "12\n",
      "15\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 12, 15, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 2]\n",
      "8\n",
      "12\n",
      "19\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 12, 19, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 2]\n",
      "8\n",
      "12\n",
      "15\n",
      "19\n",
      "22\n",
      "24\n",
      "25\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[8, 12, 15, 19, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "[0]\n",
      "[0, 2]\n",
      "[0, 2, 3]\n",
      "12\n",
      "22\n",
      "24\n",
      "25\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[12, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ec66f79065fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mboruta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#creo un array lungo quanto le features in cui andrò a salvare il numero di volte in cui una features è stata selezionata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcontaboruta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m41\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-998bebb6f30e>\u001b[0m in \u001b[0;36mboruta\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                     \u001b[0mX_train_selected_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_aug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_selected_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_aug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-8d749d25fe3f>\u001b[0m in \u001b[0;36maugmentation\u001b[1;34m(X_train_selected, y_train, cat_indexes)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSMOTENC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m41\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mX_train_selected_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_aug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX_train_selected_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_aug\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian_std_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         \u001b[0mX_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_features_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX_continuous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"object\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0mdtype_ohe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_continuous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "boruta()\n",
    "print()\n",
    "\n",
    "#creo un array lungo quanto le features in cui andrò a salvare il numero di volte in cui una features è stata selezionata\n",
    "contaboruta=[0]*41\n",
    "\n",
    "\n",
    "#creo degli array per salvarmi quante volte una features è stata selezionata, in base a una divisione del dataset,\n",
    "#così riuscirò a ottenere dei grafici ridotti e sensati\n",
    "primadivisioneboruta=[0]*14 #da CAT.Fever a INT.No.Symptoms + INT.Symptoms.No.days--> 26esimaposizione (quindi25)0-12+25\n",
    "secondadivisioneboruta=[0]*10 #da CAT.Pneumo.asthma a INT.No.Comorbidities 13-22\n",
    "terzadivisioneboruta=[0]*8 #23-24-26-31 no 25 CAT.Sex,INT.Age\n",
    "quartadivisioneboruta=[0]*9  #INT.ALT-NUM.Haematocrit 32-40\n",
    "\n",
    "#Le variabili sotto mi servono per tener conto fin dove sono arrivato a riempire i vari array.\n",
    "a=0\n",
    "primo=0\n",
    "secondo=0\n",
    "terzo=0\n",
    "quarto=0\n",
    "\n",
    "for i in features:\n",
    "  c=parzial_featuresboruta.count(i)\n",
    "  contaboruta[a]=c  \n",
    "#in base alle divisioni del dataset fatte sopra riempio gli array, a seconda del valore di a.\n",
    "  if (a<=12 or a==25):\n",
    "    primadivisioneboruta[primo]=c\n",
    "    primo=primo+1\n",
    "  if(a>=13 and a<=22):\n",
    "    secondadivisioneboruta[secondo]=c\n",
    "    secondo=secondo+1\n",
    "  if(a>=23 and a<=31 and a!=25):\n",
    "    terzadivisioneboruta[terzo]=c\n",
    "    terzo=terzo+1\n",
    "  if (a>=32 and a<=40):\n",
    "    quartadivisioneboruta[quarto]=c\n",
    "    quarto=quarto+1\n",
    "  print(i,'        ', c, c/(nit*n_fold))\n",
    "  a=a+1  \n",
    "  if (c>90):\n",
    "    final_featuresboruta.append(i)\n",
    "print(final_featuresboruta)\n",
    "print(contaboruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe()\n",
    "print()\n",
    "#creo un array lungo qunto le features in cui andrò a salvare il numero di volte in cui una features è stata selezionata\n",
    "contarfe=[0]*41\n",
    "\n",
    "#creo degli array per salvarmi quante volte una features è stata selezionata, in base a una divisione del dataset,\n",
    "#così riuscirò a ottenere dei grafici ridotti e sensati\n",
    "\n",
    "primadivisionerfe=[0]*14 #da CAT.Fever a INT.No.Symptoms + INT.Symptoms.No.days--> 26esimaposizione (quindi25)0-12+25\n",
    "secondadivisionerfe=[0]*10 #da CAT.Pneumo.asthma a INT.No.Comorbidities 13-22\n",
    "terzadivisionerfe=[0]*8 #23-24-26-31 no 25 CAT.Sex,INT.Age\n",
    "quartadivisionerfe=[0]*9  #INT.ALT-NUM.Haematocrit 32-40\n",
    "\n",
    "#creo degli array per salvarmi il nome delle features, secondo la divisione del dataset che voglio rappresentare graficamente\n",
    "feat1=[0]*14\n",
    "feat2=[0]*10\n",
    "feat3=[0]*8\n",
    "feat4=[0]*9\n",
    "\n",
    "#Le variabili sotto mi servono per tener conto fin dove sono arrivato a riempire i vari array.\n",
    "a=0\n",
    "primo=0\n",
    "secondo=0\n",
    "terzo=0\n",
    "quarto=0\n",
    "\n",
    "for i in features:\n",
    "  c=parzial_featuresrfe.count(i)\n",
    "  contarfe[a]=c  \n",
    "    #in base alle divisioni del dataset fatte sopra riempio gli array, a seconda del valore di a.\n",
    "  if (a<=12 or a==25):\n",
    "    primadivisionerfe[primo]=c\n",
    "    feat1[primo]=i\n",
    "    primo=primo+1\n",
    "    \n",
    "  if(a>=13 and a<=22):\n",
    "    secondadivisionerfe[secondo]=c\n",
    "    feat2[secondo]=i\n",
    "    secondo=secondo+1\n",
    "    \n",
    "  if(a>=23 and a<=31 and a!=25):\n",
    "    terzadivisionerfe[terzo]=c\n",
    "    feat3[terzo]=i\n",
    "    terzo=terzo+1\n",
    "    \n",
    "  if (a>=32 and a<=40):\n",
    "    quartadivisionerfe[quarto]=c\n",
    "    feat4[quarto]=i\n",
    "    quarto=quarto+1\n",
    "    \n",
    "  print(i,'        ', c, c/(nit*n_fold))\n",
    "  a=a+1  \n",
    "  if (c>90):\n",
    "    #ottengo le features finali scelte da RFE\n",
    "    final_featuresrfe.append(i)\n",
    "print(final_featuresrfe)\n",
    "print(contarfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisco come variavile per l'asse x \n",
    "x=feat1\n",
    "legend=['Boruta','RFE']\n",
    "pos = np.arange(len(x))\n",
    "#imposto lo distanza tra le colonne\n",
    "bar_width = 0.35\n",
    "#come y scelgo i dati inerenti a feat1\n",
    "y1=primadivisioneboruta\n",
    "y2=primadivisionerfe\n",
    "plt.figure(figsize=(27,5))\n",
    "plt.bar(pos,y1,bar_width,color='blue',edgecolor='black')\n",
    "plt.bar(pos+bar_width,y2,bar_width,color='pink',edgecolor='black')\n",
    "plt.xticks(pos, x)\n",
    "#definisco le varie dimensioni per i caratteri delle figure\n",
    "plt.xlabel('Features', fontsize=16)\n",
    "plt.ylabel('Volte selezionate', fontsize=16)\n",
    "plt.title('Features rilevanti Boruta vs RFE',fontsize=18)\n",
    "plt.legend(legend,loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=feat2\n",
    "legend=['Boruta','RFE']\n",
    "pos = np.arange(len(x))\n",
    "bar_width = 0.3\n",
    "y1=secondadivisioneboruta\n",
    "y2=secondadivisionerfe\n",
    "plt.figure(figsize=(26, 5))\n",
    "plt.bar(pos,y1,bar_width,color='blue',edgecolor='black')\n",
    "plt.bar(pos+bar_width,y2,bar_width,color='pink',edgecolor='black')\n",
    "plt.xticks(pos, x)\n",
    "plt.xlabel('Features', fontsize=16)\n",
    "plt.ylabel('Volte selezionate', fontsize=16)\n",
    "plt.title('Features rilevanti Boruta vs RFE',fontsize=18)\n",
    "plt.legend(legend,loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=feat1\n",
    "legend=['Boruta','RFE']\n",
    "pos = np.arange(len(x))\n",
    "bar_width = 0.3\n",
    "y1=primadivisioneboruta\n",
    "y2=primadivisionerfe\n",
    "plt.figure(figsize=(26, 5))\n",
    "plt.bar(pos,y1,bar_width,color='blue',edgecolor='black')\n",
    "plt.bar(pos+bar_width,y2,bar_width,color='pink',edgecolor='black')\n",
    "plt.xticks(pos, x)\n",
    "plt.xlabel('Features', fontsize=16)\n",
    "plt.ylabel('Volte selezionate', fontsize=16)\n",
    "plt.title('Features rilevanti Boruta vs RFE',fontsize=18)\n",
    "plt.legend(legend,loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=feat3\n",
    "legend=['Boruta','RFE']\n",
    "pos = np.arange(len(x))\n",
    "bar_width = 0.3\n",
    "y1=terzadivisioneboruta\n",
    "y2=terzadivisionerfe\n",
    "plt.figure(figsize=(26, 5))\n",
    "plt.bar(pos,y1,bar_width,color='blue',edgecolor='black')\n",
    "plt.bar(pos+bar_width,y2,bar_width,color='pink',edgecolor='black')\n",
    "plt.xticks(pos, x)\n",
    "plt.xlabel('Features', fontsize=16)\n",
    "plt.ylabel('Numero di volte selezionate', fontsize=16)\n",
    "plt.title('Features rilevanti Boruta vs RFE',fontsize=18)\n",
    "plt.legend(legend,loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=feat4\n",
    "legend=['Boruta','RFE']\n",
    "pos = np.arange(len(x))\n",
    "bar_width = 0.3\n",
    "y1=quartadivisioneboruta\n",
    "y2=quartadivisionerfe\n",
    "plt.figure(figsize=(26, 5))\n",
    "plt.bar(pos,y1,bar_width,color='blue',edgecolor='black')\n",
    "plt.bar(pos+bar_width,y2,bar_width,color='pink',edgecolor='black')\n",
    "plt.xticks(pos, x)\n",
    "plt.xlabel('Features', fontsize=16)\n",
    "plt.ylabel('Volte selezionate', fontsize=16)\n",
    "plt.title('Features rilevanti Boruta vs RFE',fontsize=18)\n",
    "plt.legend(legend,loc=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
